{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b439967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.18)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d59f806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.8\n",
      "90100\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # 應該為 True\n",
    "print(torch.version.cuda)         # 應該列出 CUDA 版本\n",
    "print(torch.backends.cudnn.version())  # cuDNN 版本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d18a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.join(os.getcwd(), 'space_ship_game_RL')\n",
    "if script_dir not in sys.path:\n",
    "    sys.path.append(script_dir)\n",
    "\n",
    "from setting import *\n",
    "from game import Game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1809ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceShipEnv():\n",
    "    def __init__(self):\n",
    "        pygame.init()\n",
    "        pygame.font.init()\n",
    "\n",
    "        # 延後畫面初始化，等 render() 時才設置\n",
    "        self.screen = None\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.fps = FPS\n",
    "\n",
    "        self.game = Game()\n",
    "\n",
    "        self.action_space = [0, 1, 2, 3]\n",
    "        self.observation = self.game.state\n",
    "\n",
    "    def step(self, action):\n",
    "        self.game.update(action)\n",
    "\n",
    "        if self.screen is None:\n",
    "            self.game.draw()\n",
    "        else:\n",
    "            self.game.draw(self.screen)\n",
    "            self.clock.tick(self.fps)\n",
    "\n",
    "        # define the state by your game logic\n",
    "        state = self.game.state\n",
    "\n",
    "        # define the reward by your game logic\n",
    "        reward = -0.5\n",
    "         \n",
    "        \n",
    "        done = not self.game.running or self.game.score >= 10000\n",
    "        info = self.game.score\n",
    "\n",
    "        return state, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self.game = Game()\n",
    "\n",
    "        return self.game.state\n",
    "\n",
    "    def render(self):\n",
    "        if self.screen is None:\n",
    "            self.screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "            pygame.display.set_caption(\"SpaceShip RL Environment\")\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf358210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7308ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceShipEnvVector:\n",
    "    def __init__(self):\n",
    "        pygame.init()\n",
    "        pygame.font.init()\n",
    "        self.screen = None\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.fps = FPS\n",
    "        self.game = Game()\n",
    "        \n",
    "        # 狀態空間設計 - 總共50維\n",
    "        self.state_dim = 50\n",
    "        self.action_space = [0, 1, 2, 3]  # 無動作、左、右、射擊\n",
    "    \n",
    "    def get_vector_state(self):\n",
    "        \"\"\"提取向量化狀態\"\"\"\n",
    "        state = np.zeros(self.state_dim)\n",
    "        idx = 0\n",
    "        \n",
    "        # 玩家基本信息 (7維)\n",
    "        player = self.game.player.sprite\n",
    "        state[idx:idx+7] = [\n",
    "            player.rect.centerx / WIDTH,        # 玩家x位置 (標準化)\n",
    "            player.rect.centery / HEIGHT,       # 玩家y位置 (標準化)\n",
    "            player.speedx / 10.0,               # 玩家x速度\n",
    "            player.health / 100.0,              # 生命值 (標準化)\n",
    "            player.lives / 3.0,                 # 生命數 (標準化)\n",
    "            min(player.gun, 3) / 3.0,           # 槍械等級 (標準化)\n",
    "            1.0 if not player.hidden else 0.0   # 是否隱藏\n",
    "        ]\n",
    "        idx += 7\n",
    "        \n",
    "        # 最近5個石頭信息 (25維: 每個石頭5維)\n",
    "        rocks = sorted(list(self.game.rocks), \n",
    "                      key=lambda r: ((r.rect.centerx - player.rect.centerx)**2 + \n",
    "                                   (r.rect.centery - player.rect.centery)**2))[:5]\n",
    "        for i in range(5):\n",
    "            if i < len(rocks):\n",
    "                rock = rocks[i]\n",
    "                state[idx:idx+5] = [\n",
    "                    rock.rect.centerx / WIDTH,   # 石頭x位置\n",
    "                    rock.rect.centery / HEIGHT,  # 石頭y位置\n",
    "                    rock.speedx / 10.0,          # 石頭x速度\n",
    "                    rock.speedy / 10.0,          # 石頭y速度\n",
    "                    rock.radius / 50.0           # 石頭半徑\n",
    "                ]\n",
    "            idx += 5\n",
    "        \n",
    "        # 最近3個子彈信息 (12維: 每個子彈4維)\n",
    "        bullets = list(player.bullet_group)[:3]\n",
    "        for i in range(3):\n",
    "            if i < len(bullets):\n",
    "                bullet = bullets[i]\n",
    "                state[idx:idx+4] = [\n",
    "                    bullet.rect.centerx / WIDTH,  # 子彈x位置\n",
    "                    bullet.rect.centery / HEIGHT, # 子彈y位置\n",
    "                    bullet.speedy / 10.0,         # 子彈y速度\n",
    "                    1.0                           # 子彈活躍狀態\n",
    "                ]\n",
    "            idx += 4\n",
    "        \n",
    "        # 最近2個道具信息 (6維: 每個道具3維)\n",
    "        powers = list(self.game.powers)[:2]\n",
    "        for i in range(2):\n",
    "            if i < len(powers):\n",
    "                power = powers[i]\n",
    "                power_type = 1.0 if power.type == 'shield' else 0.0\n",
    "                state[idx:idx+3] = [\n",
    "                    power.rect.centerx / WIDTH,   # 道具x位置\n",
    "                    power.rect.centery / HEIGHT,  # 道具y位置\n",
    "                    power_type                    # 道具類型\n",
    "                ]\n",
    "            idx += 3\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def calculate_reward(self, prev_score, prev_health, prev_lives):\n",
    "        \"\"\"計算獎勵函數\"\"\"\n",
    "        reward = 0\n",
    "        \n",
    "        # 分數獎勵 - 主要目標\n",
    "        score_diff = self.game.score - prev_score\n",
    "        if score_diff > 0:\n",
    "            reward += score_diff * 1.0\n",
    "        \n",
    "        # 生存獎勵\n",
    "        if self.game.running:\n",
    "            reward += 3.0\n",
    "        else:\n",
    "            reward -= 500  # 死亡懲罰\n",
    "        \n",
    "        # 傷害懲罰\n",
    "        health_diff = self.game.player.sprite.health - prev_health\n",
    "        if health_diff < 0:\n",
    "            reward -= abs(health_diff) * 2.0\n",
    "        elif health_diff > 0:\n",
    "            reward += health_diff * 0.5   \n",
    "              \n",
    "        if self.game.is_power:\n",
    "            reward += 30.0\n",
    "            \n",
    "        return reward\n",
    "    \n",
    "    def step(self, action):\n",
    "        # 記錄前一步狀態\n",
    "        prev_score = self.game.score\n",
    "        prev_health = self.game.player.sprite.health\n",
    "        prev_lives = self.game.player.sprite.lives\n",
    "        \n",
    "        # 執行動作\n",
    "        self.game.update(action)\n",
    "        \n",
    "        # 繪製畫面（訓練時可以關閉以加速）\n",
    "        if self.screen is None:\n",
    "            self.game.draw()\n",
    "        else:\n",
    "            self.game.draw(self.screen)\n",
    "            self.clock.tick(self.fps)\n",
    "        \n",
    "        # 獲取新狀態\n",
    "        state = self.get_vector_state()\n",
    "        \n",
    "        # 計算獎勵\n",
    "        reward = self.calculate_reward(prev_score, prev_health, prev_lives)\n",
    "        \n",
    "        # 判斷遊戲結束\n",
    "        done = not self.game.running or self.game.score >= 10000\n",
    "        \n",
    "        # 附加信息\n",
    "        info = {'score': self.game.score}\n",
    "        \n",
    "        return state, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        self.game = Game()\n",
    "        return self.get_vector_state()\n",
    "    \n",
    "    def render(self):\n",
    "        if self.screen is None:\n",
    "            self.screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "            pygame.display.set_caption(\"SpaceShip RL Environment\")\n",
    "    \n",
    "    def close(self):\n",
    "        pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b584f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorDQN(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=128, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向量DQN模型定義（需要添加）\n",
    "class VectorDQN(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(VectorDQN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, action_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# 模型初始化修改\n",
    "state_dim = 50  # 向量狀態維度\n",
    "num_actions = 4\n",
    "model = VectorDQN(state_dim, num_actions).to(device)\n",
    "\n",
    "# 載入向量模型檢查點\n",
    "checkpoint = torch.load('checkpoint_vector_best3642.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['policy_net'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9371b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "遊戲 1: reward: 16140.0, score: 1928\n",
      "分數 1928 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 2: reward: 7822.0, score: 938\n",
      "分數 938 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 3: reward: 3229.0, score: 358\n",
      "分數 358 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 4: reward: 8963.0, score: 1212\n",
      "分數 1212 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 5: reward: 4797.0, score: 786\n",
      "分數 786 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 6: reward: 6664.0, score: 1058\n",
      "分數 1058 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 7: reward: 3059.0, score: 444\n",
      "分數 444 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 8: reward: 7683.0, score: 1080\n",
      "分數 1080 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 9: reward: 14321.5, score: 1744\n",
      "分數 1744 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 10: reward: 11029.0, score: 1302\n",
      "分數 1302 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 11: reward: 8867.0, score: 1100\n",
      "分數 1100 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 12: reward: 10627.0, score: 1342\n",
      "分數 1342 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 13: reward: 7303.5, score: 980\n",
      "分數 980 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 14: reward: 3276.0, score: 444\n",
      "分數 444 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 15: reward: 3585.0, score: 540\n",
      "分數 540 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 16: reward: 10872.0, score: 1578\n",
      "分數 1578 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 17: reward: 4546.0, score: 554\n",
      "分數 554 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 18: reward: 9159.0, score: 1284\n",
      "分數 1284 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 19: reward: 22090.0, score: 2864\n",
      "分數 2864 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 20: reward: 7849.0, score: 992\n",
      "分數 992 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 21: reward: 3226.0, score: 572\n",
      "分數 572 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 22: reward: 4238.0, score: 830\n",
      "分數 830 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 23: reward: 6476.0, score: 770\n",
      "分數 770 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n",
      "遊戲 24: reward: 13766.0, score: 1548\n",
      "分數 1548 未刷新紀錄 (最高分: 3718)，重新開始遊戲...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m state_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(state)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m q_values \u001b[38;5;241m=\u001b[39m model(state_tensor)\n\u001b[1;32m---> 20\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m next_state, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     23\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state  \u001b[38;5;66;03m# 直接使用向量狀態\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 修改後的遊戲執行迴圈\n",
    "env = SpaceShipEnvVector()\n",
    "env.render()\n",
    "frames = []\n",
    "best_score = 3718  # 記錄最高分數\n",
    "max_games = 50  # 最大遊戲次數，避免無限循環\n",
    "game_count = 0\n",
    "\n",
    "while game_count < max_games:\n",
    "    state = env.reset()  # 直接獲得50維向量，無需stack_frames\n",
    "    done = False\n",
    "    episode_frames = []\n",
    "    episode_reward = 0\n",
    "    game_count += 1\n",
    "    \n",
    "    while not done:\n",
    "        # 直接使用向量狀態，無需預處理\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        q_values = model(state_tensor)\n",
    "        action = torch.argmax(q_values, dim=1).item()\n",
    "\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        state = next_state  # 直接使用向量狀態\n",
    "        \n",
    "        episode_reward += reward\n",
    "        \n",
    "        # 抓取畫面用於影片製作\n",
    "        surface = pygame.display.get_surface()\n",
    "        frame = pygame.surfarray.array3d(surface)\n",
    "        frame = np.transpose(frame, (1, 0, 2))\n",
    "        episode_frames.append(frame)\n",
    "    \n",
    "    print(f\"遊戲 {game_count}: reward: {episode_reward:.1f}, score: {info['score']}\")\n",
    "    \n",
    "    # 如果刷新紀錄，保存frames\n",
    "    if info['score'] > best_score:\n",
    "        print(f\"刷新紀錄！新紀錄: {info['score']} (原紀錄: {best_score})\")\n",
    "        frames = episode_frames  # 保存這場遊戲的frames\n",
    "        best_score = info['score']  # 更新最高分數\n",
    "        \n",
    "        # 立即保存影片（每次刷新紀錄都保存）\n",
    "        try:\n",
    "            import imageio\n",
    "            video_path = f\"space_ship_run_rl.mp4\"\n",
    "            imageio.mimsave(video_path, frames, fps=60, quality=9)\n",
    "            print(f\"已保存影片: {video_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"保存影片時出錯: {e}\")\n",
    "    else:\n",
    "        print(f\"分數 {info['score']} 未刷新紀錄 (最高分: {best_score})，重新開始遊戲...\")\n",
    "\n",
    "\n",
    "# 最終保存影片\n",
    "try:\n",
    "    import imageio\n",
    "    video_path = f\"space_ship_run_rl_final_{best_score}.mp4\"\n",
    "    imageio.mimsave(video_path, frames, fps=60, quality=9)\n",
    "    print(f\"最終影片已保存: {video_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"保存最終影片時出錯: {e}\")\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
